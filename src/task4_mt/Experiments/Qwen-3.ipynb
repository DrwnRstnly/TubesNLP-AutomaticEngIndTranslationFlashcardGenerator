{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c70250-3633-4db2-bc19-cdff5b056d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bertscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa04cd1-6732-4179-8e7b-98e7cf61358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url_english = \"https://drive.google.com/uc?export=download&id=1J5zhBA3qvKFPbADziKRv1xBQ9A_jMdRs\"\n",
    "text = requests.get(url_english).text\n",
    "lines = text.splitlines()\n",
    "df_english = pd.DataFrame({\"text\": lines})\n",
    "url_indo = \"https://drive.google.com/uc?export=download&id=1_jMC6ImrPz2KJzj4aWFdTiPS3_2-DcG6\"\n",
    "text = requests.get(url_indo).text\n",
    "lines = text.splitlines()\n",
    "df_indo = pd.DataFrame({\"text\": lines})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026be510-d32f-4356-b74e-8f37de5d3061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Saat ini ada mencit umur 4 bulan nondiabetes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Ehud Ur, profesor kedokteran di Dalhousie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seperti halnya ahli-ahli lain, dia merasa skep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara Danius, sekretaris permanen Komite Nobel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Danius berkata, \"Saat ini kita tidak melakuka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sebelumnya, CEO Ring, Jamie Siminoff, berkomen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ia melakukan pembuatan bel pintu dengan teknol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Siminoff mengatakan penjualan meningkat setela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Di akhir tahun 2017, Siminoff muncul di salura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ring juga menyelesaikan sebuah tuntutan hukum ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  “Saat ini ada mencit umur 4 bulan nondiabetes ...\n",
       "1  Dr. Ehud Ur, profesor kedokteran di Dalhousie ...\n",
       "2  Seperti halnya ahli-ahli lain, dia merasa skep...\n",
       "3  Sara Danius, sekretaris permanen Komite Nobel ...\n",
       "4  \"Danius berkata, \"Saat ini kita tidak melakuka...\n",
       "5  Sebelumnya, CEO Ring, Jamie Siminoff, berkomen...\n",
       "6  Ia melakukan pembuatan bel pintu dengan teknol...\n",
       "7  Siminoff mengatakan penjualan meningkat setela...\n",
       "8  Di akhir tahun 2017, Siminoff muncul di salura...\n",
       "9  Ring juga menyelesaikan sebuah tuntutan hukum ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2871370-df86-4a4e-bf66-e92105d39de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989f859fb1804fb385a6a616ffd9a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7471b54-49a3-4369-bf97-bd2fcee5c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT = \"\"\"\n",
    "English: In 2010, South Korea experienced a particularly cold winter.\n",
    "Indonesian: Pada 2010, Korea Selatan mengalami musim dingin yang tidak biasa.\n",
    "\n",
    "English: People couldn't activate their smartphones while wearing gloves, \n",
    "so they began wielding snack sausages—causing one company to see a 40% rise in sausage sales.\n",
    "Indonesian: Orang-orang tidak dapat menyalakan ponsel pintar mereka saat mengenakan sarung tangan, \n",
    "jadi mereka mulai menggunakan camilan sosis, yang menyebabkan satu perusahaan mengalami kenaikan penjualan sosis sebesar 40%.\n",
    "\"\"\".strip()\n",
    "\n",
    "def prompt_zero_shot(text):\n",
    "    return f\"\"\"Translate to Indonesian:\n",
    "\n",
    "English: \"{text}\"\n",
    "Indonesian:\"\"\".strip()\n",
    "\n",
    "def prompt_few_shot(text):\n",
    "    return f\"\"\"Translate English to Indonesian following the examples.\n",
    "\n",
    "{FEW_SHOT}\n",
    "\n",
    "English: \"{text}\"\n",
    "Indonesian:\"\"\".strip()\n",
    "\n",
    "def prompt_role_based(text):\n",
    "    return f\"\"\"You are a professional bilingual educator who creates flashcards.\n",
    "Translate the English sentence into natural Indonesian.\n",
    "Use complete sentences. No explanation. Output ONLY Indonesian.\n",
    "\n",
    "English: \"{text}\"\n",
    "Indonesian:\"\"\".strip()\n",
    "\n",
    "def prompt_cot_guarded(text):\n",
    "    return f\"\"\"Translate the English sentence into Indonesian.\n",
    "First think through the meaning step-by-step to ensure accuracy.\n",
    "Then provide the final Indonesian translation ONLY in the last line, prefixed with \"Indonesian:\".\n",
    "\n",
    "English: \"{text}\"\n",
    "\n",
    "Reasoning:\n",
    "\"\"\".strip()\n",
    "\n",
    "def prompt_back_translation(text):\n",
    "    return f\"\"\"Step 1: Translate the English sentence to Indonesian.\n",
    "Step 2: Translate that Indonesian back to English to verify consistency.\n",
    "Step 3: Output ONLY the final Indonesian translation in the last line, prefixed with \"Final Indonesian:\".\n",
    "\n",
    "English: \"{text}\"\n",
    "\n",
    "Indonesian:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900b4a8-32c6-480b-972c-87e2eb4f45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_back_translation(gen):\n",
    "    if not isinstance(gen, str):\n",
    "        return \"\"\n",
    "\n",
    "    m = re.search(r'Final Indonesian\\s*:\\s*\"([^\"]+)\"', gen, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "\n",
    "    m2 = re.search(r'Indonesian\\s*:\\s*\"([^\"]+)\"', gen, flags=re.I)\n",
    "    if m2:\n",
    "        return m2.group(1).strip()\n",
    "    m3 = re.search(r'\"([^\"]+)\"', gen)\n",
    "    if m3:\n",
    "        return m3.group(1).strip()\n",
    "    return gen.split(\"\\n\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cbd3f-6470-4e8a-b88a-fd66ad36fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_wrappers(s: str):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    s = s.lstrip(\"['\").rstrip(\"']\")\n",
    "    s = s.strip()\n",
    "    s = s.strip('\"').strip(\"'\").strip()\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07fe89ff-2bea-4ea0-9c84-ec5942d76207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_new_tokens=60):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.0,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "def extract_translation(full_output, prompt, method):\n",
    "    gen = full_output.replace(prompt, \"\").strip()\n",
    "\n",
    "    gen = re.sub(r\"\\r\\n?\", \"\\n\", gen).strip()\n",
    "\n",
    "    if method in [\"zero_shot\", \"few_shot\", \"role_based\"]:\n",
    "        lines = [l.strip() for l in gen.split(\"\\n\") if l.strip()]\n",
    "        if not lines:\n",
    "            return \"\"\n",
    "        m = re.match(r'^(Indonesian|Indonesia|Terjemahan|Translation)\\s*:\\s*(.*)$', lines[0], re.I)\n",
    "        return strip_wrappers((m.group(2).strip() if m else lines[0]))\n",
    "    if method == \"back_translation\":\n",
    "        return strip_wrappers(extract_back_translation(gen))\n",
    "    return gen.split(\"\\n\")[0].strip()\n",
    "\n",
    "def generate_only_translation(prompt, method, max_new_tokens=160):\n",
    "    full_output = generate_text(prompt, max_new_tokens=max_new_tokens)\n",
    "    return extract_translation(full_output, prompt, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca9e7c3-f8e6-43fe-a79a-d4b92238a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = SmoothingFunction().method1\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "def compute_bleu(ref, hypo):\n",
    "    return sentence_bleu([ref.split()], hypo.split(), smoothing_function=smooth)\n",
    "\n",
    "def compute_rougeL(ref, hypo):\n",
    "    return rouge.score(ref, hypo)[\"rougeL\"].fmeasure\n",
    "\n",
    "def compute_bertscore(ref, hypo):\n",
    "    P, R, F1 = bertscore([hypo], [ref], lang=\"id\")\n",
    "    return F1[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a68e4-1df1-461f-b352-5e17ccba0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_pipeline(df_en, df_id, method_name):\n",
    "    methods = {\n",
    "        \"zero_shot\": prompt_zero_shot,\n",
    "        \"few_shot\": prompt_few_shot,\n",
    "        \"role_based\": prompt_role_based,\n",
    "        \"back_translation\": prompt_back_translation,\n",
    "    }\n",
    "\n",
    "    if method_name not in methods:\n",
    "        raise ValueError(f\"Invalid method. Choose from: {list(methods.keys())}\")\n",
    "\n",
    "    method_func = methods[method_name]\n",
    "\n",
    "    all_outputs = []\n",
    "    bleu_list, rouge_list, bert_list = [], [], []\n",
    "\n",
    "    print(f\"\\n=== RUNNING {method_name.upper()} (NO BATCHING) ===\")\n",
    "\n",
    "    for i in tqdm(range(len(df_en))):\n",
    "\n",
    "        en = df_en.loc[i, \"text\"]\n",
    "        gt = df_id.loc[i, \"text\"]\n",
    "\n",
    "        prompt = method_func(en)\n",
    "        full_output = generate_text(prompt, max_new_tokens=60)\n",
    "        pred = extract_translation(full_output, prompt, method_name)\n",
    "\n",
    "        all_outputs.append(pred)\n",
    "\n",
    "        bleu_list.append(compute_bleu(gt, pred))\n",
    "        rouge_list.append(compute_rougeL(gt, pred))\n",
    "        bert_list.append(compute_bertscore(gt, pred))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # aggregate\n",
    "    scores = {\n",
    "        \"bleu\": float(np.mean(bleu_list)),\n",
    "        \"rougeL\": float(np.mean(rouge_list)),\n",
    "        \"bertscore\": float(np.mean(bert_list)),\n",
    "    }\n",
    "\n",
    "    return all_outputs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892646cc-dd6a-4906-bb5f-54c8c11a536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\"\n",
    "def generate_batch(prompts, max_new_tokens=60):\n",
    "    inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            use_cache=False,   \n",
    "        )\n",
    "\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06d26a-83e6-4f43-b947-5904088c7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batched_pipeline(df_en, df_id, method_name, batch_size=4):\n",
    "    methods = {\n",
    "        \"zero_shot\": prompt_zero_shot,\n",
    "        \"few_shot\": prompt_few_shot,\n",
    "        \"role_based\": prompt_role_based,\n",
    "        \"back_translation\": prompt_back_translation,\n",
    "    }\n",
    "\n",
    "    if method_name not in methods:\n",
    "        raise ValueError(f\"Invalid method. Choose from: {list(methods.keys())}\")\n",
    "\n",
    "    method_func = methods[method_name]\n",
    "\n",
    "    all_outputs = []\n",
    "    bleu_list, rouge_list, bert_list = [], [], []\n",
    "\n",
    "    print(f\"\\n=== RUNNING {method_name.upper()} | BATCH SIZE = {batch_size} ===\")\n",
    "\n",
    "    num_samples = len(df_en)\n",
    "\n",
    "    for start in tqdm(range(0, num_samples, batch_size)):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "\n",
    "        en_batch = [df_en.loc[i, \"text\"] for i in range(start, end)]\n",
    "        gt_batch = [df_id.loc[i, \"text\"] for i in range(start, end)]\n",
    "\n",
    "        prompts = [method_func(en) for en in en_batch]\n",
    "\n",
    "        raw_outputs = generate_batch(prompts, max_new_tokens=60)\n",
    "\n",
    "        preds = [\n",
    "            extract_translation(raw_outputs[j], prompts[j], method_name)\n",
    "            for j in range(len(raw_outputs))\n",
    "        ]\n",
    "\n",
    "        all_outputs.extend(preds)\n",
    "\n",
    "        for j in range(len(preds)):\n",
    "            bleu_list.append(compute_bleu(gt_batch[j], preds[j]))\n",
    "            rouge_list.append(compute_rougeL(gt_batch[j], preds[j]))\n",
    "            bert_list.append(compute_bertscore(gt_batch[j], preds[j]))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    scores = {\n",
    "        \"bleu\": float(np.mean(bleu_list)),\n",
    "        \"rougeL\": float(np.mean(rouge_list)),\n",
    "        \"bertscore\": float(np.mean(bert_list)),\n",
    "    }\n",
    "\n",
    "    return all_outputs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "515ac48e-3932-4bb8-bf0e-195f29108fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_methods(df_en, df_id, batch_size=4):\n",
    "    methods = [\"zero_shot\", \"few_shot\", \"role_based\", \"back_translation\"]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for m in methods:\n",
    "        print(f\"\\n========== Evaluating {m.upper()} ==========\")\n",
    "        outputs, scores = run_batched_pipeline(df_en, df_id, m, batch_size=batch_size)\n",
    "        results[m] = scores\n",
    "        print(scores)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf5ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to identic_en_id.csv\n",
      "\n",
      "                                             english  \\\n",
      "0  Delhi ropes in monkeys for Commonwealth Games ...   \n",
      "1  Delhi authorities have deployed a contingent o...   \n",
      "2  At least 10 langurs have been on duty outside ...   \n",
      "3  Delhi civic authorities have 28 langurs and 10...   \n",
      "4  Thousands of monkeys roam Delhi, mostly around...   \n",
      "\n",
      "                                          indonesian  \n",
      "0                  Kera untuk amankan pesta olahraga  \n",
      "1  Pemerintah kota Delhi mengerahkan monyet untuk...  \n",
      "2  Beberapa laporan menyebutkan setidaknya 10 mon...  \n",
      "3  Pemkot Delhi memiliki 28 monyet dan berencana ...  \n",
      "4  Jumlah monyet di ibukota India mencapai ribuan...  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "dset = load_dataset(\"SEACrowd/identic\", trust_remote_code=True)\n",
    "train = dset[\"train\"]\n",
    "pairs = []\n",
    "for i in train:\n",
    "    pairs.append({\n",
    "        \"english\": i[\"en_sentence\"],\n",
    "        \"indonesian\": i[\"id_sentence\"]\n",
    "    })\n",
    "df = pd.DataFrame(pairs)\n",
    "df.to_csv(\"identic_en_id.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved to identic_en_id.csv\")\n",
    "print()\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3841b6cb-6caa-4479-8d29-d383fb28b743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Evaluating ZERO_SHOT ==========\n",
      "\n",
      "=== RUNNING ZERO_SHOT | BATCH SIZE = 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/169 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|██████████| 169/169 [34:07<00:00, 12.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.21997517773039588, 'rougeL': 0.5819825048123606, 'bertscore': 0.8749076050260792}\n",
      "\n",
      "========== Evaluating FEW_SHOT ==========\n",
      "\n",
      "=== RUNNING FEW_SHOT | BATCH SIZE = 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [39:42<00:00, 14.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.21584506595623718, 'rougeL': 0.5721688444213027, 'bertscore': 0.8644501088047216}\n",
      "\n",
      "========== Evaluating ROLE_BASED ==========\n",
      "\n",
      "=== RUNNING ROLE_BASED | BATCH SIZE = 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [35:18<00:00, 12.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.2143740261448708, 'rougeL': 0.5801238872723201, 'bertscore': 0.8742129639556757}\n",
      "\n",
      "========== Evaluating BACK_TRANSLATION ==========\n",
      "\n",
      "=== RUNNING BACK_TRANSLATION | BATCH SIZE = 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [35:04<00:00, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.2003157764682237, 'rougeL': 0.5421106435793569, 'bertscore': 0.858647780279397}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_all_methods(df_english, df_indo, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37651e7c-1fe0-4de1-8c20-6c9b7341ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_zero, scores_zero = run_single_pipeline(df_english, df_indo, \"zero_shot\")\n",
    "# print(scores_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dcc1926-37cf-4c19-b413-e31c7650058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_few, scores_few = run_single_pipeline(df_english, df_indo, \"few_shot\")\n",
    "# print(scores_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a628dfa-2918-4b1b-9f0a-4478a570be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_role, scores_role = run_single_pipeline(df_english, df_indo, \"role_based\")\n",
    "# print(scores_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29efd726-8848-4201-ac2a-8dab3e8add46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_back, scores_back = run_single_pipeline(df_english, df_indo, \"back_translation\")\n",
    "# print(scores_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e72017b-1de4-4e05-b342-f672d24744c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_one_en = df_english.iloc[[0]]\n",
    "# df_one_id = df_indo.iloc[[0]]\n",
    "\n",
    "# outputs, scores = run_batched_pipeline(df_one_en, df_one_id, \"zero_shot\", batch_size=1)\n",
    "# print(outputs)\n",
    "# print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
